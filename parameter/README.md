
## Parameter Optimization
1. Gradient Decent</br>
2. Stochastic Gradient Descent (SGD)</br>
3. Mini-Batch Gradient Descent</br>
4. Conjugate Gradient Descent</br>
5. Quasi-Newton Methods (like BFGS)</br>

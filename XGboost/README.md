# XGBoost
XGBoost

Parameters tunning:
1) max_depth =
2) n_estimator = 
1) subsample = 0.75 e.g. row sampling
2) gamma = 0.25 e.g. increase gamma --> less splits / less complex (reduce overfitting)
3) learning rate (it should be runned together with the number of trees)
4) reg_alph = l1 regression

Hyper parameters
Methods
1) Grid search
2) Random search

![Image 2023-11-05 at 9 45 PM](https://github.com/scottmsoh/XGBoost/assets/112598791/04ea074f-1ba3-4b63-a15e-f25608579681)

![Image 2023-11-05 at 9 59 PM](https://github.com/scottmsoh/XGBoost/assets/112598791/7edede6f-6b2c-41cb-977f-14191cfd6ff3)

